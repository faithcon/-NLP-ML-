{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f263aec-f452-4131-9661-68ff4bb5a5be",
   "metadata": {},
   "source": [
    "**Regular Expressions in NLP Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbdf58c7-c815-46bb-9727-6a5dbcb5f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Sample text from the chosen paragraph\n",
    "text = \"\"\"This chapter outlines the methodology used in the development of the system. It includes details on the adopted methodology, data collection, preprocessing techniques, CNN architecture, and evaluation metrics. The Rapid Application Development (RAD) methodology was employed to ensure iterative progress and adaptability throughout the project lifecycle.\n",
    "\n",
    "The system development process followed the Rapid Application Development (RAD) methodology, focusing on iterative development and rapid prototyping. The primary steps included:\n",
    "\n",
    "1. Dataset Preparation: The Potato Leaf Images Dataset was downloaded from Kaggle and stored in Google Drive for easy access.\n",
    "2. Data Preprocessing: Techniques such as auto-orientation, resizing, and data augmentation were applied to enhance dataset quality.\n",
    "3. Model Training and Validation: The CNN model was trained and validated using Google Colab, leveraging the augmented dataset.\n",
    "4. Model Testing: The trained model was evaluated on a separate test set to ensure robustness and reliability.\n",
    "\n",
    "The PlantVillage dataset was utilized as the primary data source for this study. Developed by Penn State University and EPFL, the dataset contains 38 classes of diseased and healthy leaves from 14 plants. For this research, the focus was on potato crops, with the following distribution:\n",
    "\n",
    "- Early Blight: 1,000 images\n",
    "- Late Blight: 1,000 images\n",
    "- Healthy: 152 images\n",
    "\n",
    "To address overfitting and improve the diversity of the training set, various augmentation techniques were applied using the Keras ImageDataGenerator. These included:\n",
    "\n",
    "- Rotation: Rotating images at specific angles to account for variations in how objects might appear in real-world scenarios.\n",
    "- Shifting: Randomly moving images within a defined range, horizontally or vertically.\n",
    "- Shear Transformation: Stretching one axis of the image to simulate distortions.\n",
    "- Zoom: Magnifying parts of the image to focus on finer details.\n",
    "- Flipping: Horizontally flipping images to ensure the model becomes invariant to directional changes.\n",
    "- Brightness Adjustment: Modifying brightness levels to simulate varying lighting conditions.\n",
    "\n",
    "Evaluation metrics play a crucial role in assessing model performance. The following metrics were employed:\n",
    "\n",
    "1. Classification Accuracy: Calculated as the ratio of correctly predicted samples to the total number of predictions.\n",
    "2. Precision: Measures the consistency of the model in identifying true positives, particularly important in imbalanced datasets.\n",
    "3. Recall: Indicates the proportion of actual positives correctly identified by the model.\n",
    "4. F1 Score: Combines precision and recall to provide a balanced evaluation.\n",
    "\n",
    "The proposed CNN model comprises three convolutional layers, each followed by Rectified Linear Unit (ReLU) activation and max-pooling layers. Key components include:\n",
    "\n",
    "- Flatten Layer: Converts the convolved matrix into a one-dimensional array.\n",
    "- Fully Connected Layers: Three dense layers with ReLU activation, followed by an output layer with Softmax activation.\n",
    "\n",
    "The CNN configuration includes:\n",
    "\n",
    "- Convolution Layers: 3 layers with 3 × 3 filters each.\n",
    "- Max-Pooling Layers: 3 layers with 2 × 2 pool sizes each.\n",
    "- Fully Connected Layers: 512, 256, and 128 neurons, respectively.\n",
    "- Output Layer Activation: Softmax.\n",
    "- Batch Size: 32.\n",
    "- Epochs: 50.\n",
    "- Optimizer: Adam.\n",
    "- Loss Function: Categorical Cross-Entropy.\n",
    "\n",
    "Through these carefully selected methodologies and configurations, the model ensures robustness, accuracy, and practical usability in identifying potato leaf diseases. This approach, combined with iterative development, aligns with the project’s goal of enhancing agricultural productivity through advanced machine learning techniques.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28262f01-ac13-4fb1-9e83-85fdd39636b0",
   "metadata": {},
   "source": [
    "**Task 1: Extracting capitalized words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ddb1ec2-4edf-43c5-8a6a-0a07125c5abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capitalized Words: ['This', 'It', 'The', 'Rapid', 'Application', 'Development', 'The', 'Rapid', 'Application', 'Development', 'The', 'Dataset', 'Preparation', 'The', 'Potato', 'Leaf', 'Images', 'Dataset', 'Kaggle', 'Google', 'Drive', 'Data', 'Preprocessing', 'Techniques', 'Model', 'Training', 'Validation', 'The', 'Google', 'Colab', 'Model', 'Testing', 'The', 'The', 'Developed', 'Penn', 'State', 'University', 'For', 'Early', 'Blight', 'Late', 'Blight', 'Healthy', 'To', 'Keras', 'These', 'Rotation', 'Rotating', 'Shifting', 'Randomly', 'Shear', 'Transformation', 'Stretching', 'Zoom', 'Magnifying', 'Flipping', 'Horizontally', 'Brightness', 'Adjustment', 'Modifying', 'Evaluation', 'The', 'Classification', 'Accuracy', 'Calculated', 'Precision', 'Measures', 'Recall', 'Indicates', 'Score', 'Combines', 'The', 'Rectified', 'Linear', 'Unit', 'Key', 'Flatten', 'Layer', 'Converts', 'Fully', 'Connected', 'Layers', 'Three', 'Softmax', 'The', 'Convolution', 'Layers', 'Max', 'Pooling', 'Layers', 'Fully', 'Connected', 'Layers', 'Output', 'Layer', 'Activation', 'Softmax', 'Batch', 'Size', 'Epochs', 'Optimizer', 'Adam', 'Loss', 'Function', 'Categorical', 'Cross', 'Entropy', 'Through', 'This']\n",
      "Total Number of Capitalized Words: 110\n"
     ]
    }
   ],
   "source": [
    "capitalized_words = re.findall(r'\\b[A-Z][a-z]*\\b', text)\n",
    "print(\"Capitalized Words:\", capitalized_words)\n",
    "\n",
    "# Count the total number of capitalized words\n",
    "capitalized_word_count = len(capitalized_words)\n",
    "print(\"Total Number of Capitalized Words:\", capitalized_word_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4c2af-2375-43b7-bde6-096fefbebfcd",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "    Regex Pattern: \\b[A-Z][a-z]*\\b\n",
    "        \\b: Matches word boundaries to ensure complete words are captured.\n",
    "        [A-Z]: Matches the first letter as uppercase.\n",
    "        [a-z]*: Matches zero or more lowercase letters following the uppercase letter.\n",
    "        Combined, this identifies words that start with a capital letter.\n",
    "**Purpose**: \n",
    "    This operation identifies proper nouns, acronyms, and the first words of sentences. These are useful in NLP tasks such as Named Entity Recognition (NER) or identifying significant terms in a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2499c89-b641-4cc8-9c95-120a4c82bbaa",
   "metadata": {},
   "source": [
    "**Task 2: Extracting sentences containing the word \"data\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "867df24d-cce8-4cf2-80d4-d7ba0f130031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Sentences containing 'data': ['This chapter outlines the methodology used in the development of the system. It includes details on the adopted methodology, data collection, preprocessing techniques, CNN architecture, and evaluation metrics.', '2. Data Preprocessing: Techniques such as auto-orientation, resizing, and data augmentation were applied to enhance dataset quality.', 'The PlantVillage dataset was utilized as the primary data source for this study.']\n",
      "Total Number of Sentences containing 'data': 3\n"
     ]
    }
   ],
   "source": [
    "sentences_with_data = re.findall(r'.*?\\bdata\\b.*?[.?!]', text, flags=re.IGNORECASE)\n",
    "print(\"2. Sentences containing 'data':\", sentences_with_data)\n",
    "\n",
    "#total number of sentences containing \"data\"\n",
    "sentence_count = len(sentences_with_data)\n",
    "print(\"Total Number of Sentences containing 'data':\", sentence_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b843643-e8ee-4e18-bc2a-0e8142b35387",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "    Regex Pattern:\n",
    "        .*?: Matches any character (non-greedy).\n",
    "        \\bdata\\b: Matches the exact word \"data\" (case-insensitive because of flags=re.IGNORECASE).\n",
    "        .*?[.?!]: Matches everything after \"data\" up to the next sentence-ending punctuation (., ?, or !).\n",
    "**Purpose** \n",
    "    Extracting sentences with specific keywords is useful in text mining, summarization, and finding context for terms in NLP tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feec569-8045-4685-a362-660be04fea43",
   "metadata": {},
   "source": [
    "**Task 3: Extracting Numeric Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "041dd828-dd2c-4e78-b922-84c917660e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Values: ['1', '2', '3', '4', '38', '14', '1', '000', '1', '000', '152', '1', '2', '3', '4', '3', '3', '3', '3', '2', '2', '512', '256', '128', '32', '50']\n",
      "Total Number of Numeric Values: 26\n"
     ]
    }
   ],
   "source": [
    "#Extract all numeric values (including integers and decimals)\n",
    "numeric_values = re.findall(r'\\b\\d+(?:\\.\\d+)?\\b', text)\n",
    "print(\"Numeric Values:\", numeric_values)\n",
    "\n",
    "# Counting the total number of numeric values\n",
    "numeric_count = len(numeric_values)\n",
    "print(\"Total Number of Numeric Values:\", numeric_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f356c46-d0b2-42e2-acbe-9030ac2cdf88",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "Regex Pattern: \\b\\d+(?:\\.\\d+)?\\b\n",
    "\n",
    "\\b: Matches word boundaries to ensure complete numbers are captured.\n",
    "\\d+: Matches one or more digits.\n",
    "(?:\\.\\d+)?: Matches a decimal point followed by one or more digits (optional).\n",
    "Combined, this identifies integers and decimals.\n",
    "Purpose:\n",
    "\n",
    "This operation extracts numeric data, useful for analyzing statistical and measurement-related information in text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b1983-3ec8-4267-b66c-e6ef3ff65286",
   "metadata": {},
   "source": [
    "**Task 4: Replace Repeated Spaces or Empty Lines with a Single Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0266701-f096-4ada-9ba7-4e0116f44361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text After Normalizing Spacing:\n",
      " This chapter outlines the methodology used in the development of the system. It includes details on the adopted methodology, data collection, preprocessing techniques, CNN architecture, and evaluation metrics. The Rapid Application Development (RAD) methodology was employed to ensure iterative progress and adaptability throughout the project lifecycle. The system development process followed the Rapid Application Development (RAD) methodology, focusing on iterative development and rapid prototyp\n"
     ]
    }
   ],
   "source": [
    "# Normalizing spacing by removing repeated spaces and empty lines\n",
    "text_normalized_spacing = re.sub(r'\\s+', ' ', text)\n",
    "print(\"Text After Normalizing Spacing:\\n\", text_normalized_spacing[:500])  # Displaying only the first 500 characters for brevity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8288e799-1aeb-47b1-b66d-0512df5b6df5",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "Regex Pattern: \\s+\n",
    "Matches one or more whitespace characters, including spaces, tabs, or newlines.\n",
    "Replaces multiple spaces or empty lines with a single space, producing cleaner text.\n",
    "\n",
    "**Purpose**: \n",
    "Streamline text for NLP pipelines, ensuring consistency in spacing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff18d100-f91a-4b48-b890-5d0dc94fe74e",
   "metadata": {},
   "source": [
    "**Task 5: Counting the Occurrences of the Word “model”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "258aecac-5bda-4239-b802-a4eea6ecf363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of 'model': 10\n"
     ]
    }
   ],
   "source": [
    "model_count = len(re.findall(r'\\bmodel\\b', text, flags=re.IGNORECASE))\n",
    "print(\"Occurrences of 'model':\", model_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999ff718-6c30-4423-9969-a7a3b7ecf63f",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Regex Pattern:** \\bmodel\\b\n",
    "\n",
    "\\b: Ensures \"model\" is matched as a complete word.\n",
    "IGNORECASE: Enables case-insensitive matching.\n",
    "\n",
    "**Purpose:** Determine the frequency of key terms to gauge their significance in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726532c-1537-4afd-b369-3b2552954a3a",
   "metadata": {},
   "source": [
    "**Task 6: Replacing All Numerical Values with a Placeholder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "868e088d-0ecb-4d13-a35e-8d47d41aa9b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with Numerical Values Replaced: This chapter outlines the methodology used in the development of the system. It includes details on the adopted methodology, data collection, preprocessing techniques, CNN architecture, and evaluation metrics. The Rapid Application Development (RAD) methodology was employed to ensure iterative progress and adaptability throughout the project lifecycle.\n",
      "\n",
      "The system development process followed the Rapid Application Development (RAD) methodology, focusing on iterative development and rapid prototyping. The primary steps included:\n",
      "\n",
      "<NUM>. Dataset Preparation: The Potato Leaf Images Dataset was downloaded from Kaggle and stored in Google Drive for easy access.\n",
      "<NUM>. Data Preprocessing: Techniques such as auto-orientation, resizing, and data augmentation were applied to enhance dataset quality.\n",
      "<NUM>. Model Training and Validation: The CNN model was trained and validated using Google Colab, leveraging the augmented dataset.\n",
      "<NUM>. Model Testing: The trained model was evaluated on a separate test set to ensure robustness and reliability.\n",
      "\n",
      "The PlantVillage dataset was utilized as the primary data source for this study. Developed by Penn State University and EPFL, the dataset contains <NUM> classes of diseased and healthy leaves from <NUM> plants. For this research, the focus was on potato crops, with the following distribution:\n",
      "\n",
      "- Early Blight: <NUM>,<NUM> images\n",
      "- Late Blight: <NUM>,<NUM> images\n",
      "- Healthy: <NUM> images\n",
      "\n",
      "To address overfitting and improve the diversity of the training set, various augmentation techniques were applied using the Keras ImageDataGenerator. These included:\n",
      "\n",
      "- Rotation: Rotating images at specific angles to account for variations in how objects might appear in real-world scenarios.\n",
      "- Shifting: Randomly moving images within a defined range, horizontally or vertically.\n",
      "- Shear Transformation: Stretching one axis of the image to simulate distortions.\n",
      "- Zoom: Magnifying parts of the image to focus on finer details.\n",
      "- Flipping: Horizontally flipping images to ensure the model becomes invariant to directional changes.\n",
      "- Brightness Adjustment: Modifying brightness levels to simulate varying lighting conditions.\n",
      "\n",
      "Evaluation metrics play a crucial role in assessing model performance. The following metrics were employed:\n",
      "\n",
      "<NUM>. Classification Accuracy: Calculated as the ratio of correctly predicted samples to the total number of predictions.\n",
      "<NUM>. Precision: Measures the consistency of the model in identifying true positives, particularly important in imbalanced datasets.\n",
      "<NUM>. Recall: Indicates the proportion of actual positives correctly identified by the model.\n",
      "<NUM>. F1 Score: Combines precision and recall to provide a balanced evaluation.\n",
      "\n",
      "The proposed CNN model comprises three convolutional layers, each followed by Rectified Linear Unit (ReLU) activation and max-pooling layers. Key components include:\n",
      "\n",
      "- Flatten Layer: Converts the convolved matrix into a one-dimensional array.\n",
      "- Fully Connected Layers: Three dense layers with ReLU activation, followed by an output layer with Softmax activation.\n",
      "\n",
      "The CNN configuration includes:\n",
      "\n",
      "- Convolution Layers: <NUM> layers with <NUM> × <NUM> filters each.\n",
      "- Max-Pooling Layers: <NUM> layers with <NUM> × <NUM> pool sizes each.\n",
      "- Fully Connected Layers: <NUM>, <NUM>, and <NUM> neurons, respectively.\n",
      "- Output Layer Activation: Softmax.\n",
      "- Batch Size: <NUM>.\n",
      "- Epochs: <NUM>.\n",
      "- Optimizer: Adam.\n",
      "- Loss Function: Categorical Cross-Entropy.\n",
      "\n",
      "Through these carefully selected methodologies and configurations, the model ensures robustness, accuracy, and practical usability in identifying potato leaf diseases. This approach, combined with iterative development, aligns with the project’s goal of enhancing agricultural productivity through advanced machine learning techniques.\n"
     ]
    }
   ],
   "source": [
    "placeholder_text = re.sub(r'\\b\\d+(?:\\.\\d+)?\\b', '<NUM>', text)\n",
    "print(\"Text with Numerical Values Replaced:\", placeholder_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead64d37-5d2f-45a4-8325-c85e96619a5a",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Regex Pattern:** \\b\\d+(?:\\.\\d+)?\\b\n",
    "\n",
    "Matches integers and decimals.\n",
    "    \n",
    "**Purpose:** Mask numerical values for anonymization or normalization tasks in text processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565bef9f-db75-4de3-b936-5b01a6db12cf",
   "metadata": {},
   "source": [
    "**Task 7: Extracting Acronyms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cd2b3f2-b646-47a2-9290-cc8909855359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acronyms: ['CNN', 'RAD', 'RAD', 'CNN', 'EPFL', 'CNN', 'CNN']\n",
      "Total Number of Acronyms: 7\n"
     ]
    }
   ],
   "source": [
    "acronyms = re.findall(r'\\b[A-Z]{2,}\\b', text)\n",
    "print(\"Acronyms:\", acronyms)\n",
    "\n",
    "# Count the total number of acronyms\n",
    "acronym_count = len(acronyms)\n",
    "print(\"Total Number of Acronyms:\", acronym_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89762593-10f3-4ada-bbe4-8000933c5b1d",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Regex Pattern:** \\b[A-Z]{2,}\\b\n",
    "\n",
    "Matches sequences of two or more consecutive uppercase letters.\n",
    "\n",
    "**Purpose:**\n",
    "Identify abbreviations or acronyms, which are essential for understanding domain-specific terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8bb7ce-b829-41e8-9bed-90db10be108a",
   "metadata": {},
   "source": [
    "**Task 8: Finding Words With Hyphens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e98fbb2d-d7bc-4734-bff9-05cb7109dd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyphenated Words: ['auto-orientation', 'real-world', 'max-pooling', 'one-dimensional', 'Max-Pooling', 'Cross-Entropy']\n",
      "Total Number of Hyphenated Words: 6\n"
     ]
    }
   ],
   "source": [
    "hyphenated_words = re.findall(r'\\b\\w+-\\w+\\b', text)\n",
    "print(\"Hyphenated Words:\", hyphenated_words)\n",
    "\n",
    "# Count the total number of hyphenated words\n",
    "hyphenated_word_count = len(hyphenated_words)\n",
    "print(\"Total Number of Hyphenated Words:\", hyphenated_word_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c7a4ab-9523-4308-b18f-7989146c68fd",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Regex Pattern:** \\b\\w+-\\w+\\b\n",
    "\n",
    "Matches words with at least one hyphen and ensures complete word boundaries.\n",
    "\n",
    "**Purpose:** Extract hyphenated terms that often represent compound words or specialized terminology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236fb337-e4f6-4c13-b44c-7ae902ea4889",
   "metadata": {},
   "source": [
    "**Task 9:Extracting Nouns Using Heuristics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4ce25d3-27e0-4d97-8465-0d87a8c6503f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun Candidates: ['This', 'It', 'The', 'Rapid', 'Application', 'Development', 'The', 'Rapid', 'Application', 'Development', 'The', 'Dataset', 'Preparation', 'The', 'Potato', 'Leaf', 'Images', 'Dataset', 'Kaggle', 'Google', 'Drive', 'Data', 'Preprocessing', 'Techniques', 'Model', 'Training', 'Validation', 'The', 'Google', 'Colab', 'Model', 'Testing', 'The', 'The', 'Developed', 'Penn', 'State', 'University', 'For', 'Early', 'Blight', 'Late', 'Blight', 'Healthy', 'To', 'Keras', 'These', 'Rotation', 'Rotating', 'Shifting', 'Randomly', 'Shear', 'Transformation', 'Stretching', 'Zoom', 'Magnifying', 'Flipping', 'Horizontally', 'Brightness', 'Adjustment', 'Modifying', 'Evaluation', 'The', 'Classification', 'Accuracy', 'Calculated', 'Precision', 'Measures', 'Recall', 'Indicates', 'Score', 'Combines', 'The', 'Rectified', 'Linear', 'Unit', 'Key', 'Flatten', 'Layer', 'Converts', 'Fully', 'Connected', 'Layers', 'Three', 'Softmax', 'The', 'Convolution', 'Layers', 'Max', 'Pooling', 'Layers', 'Fully', 'Connected', 'Layers', 'Output', 'Layer', 'Activation', 'Softmax', 'Batch', 'Size', 'Epochs', 'Optimizer', 'Adam', 'Loss', 'Function', 'Categorical', 'Cross', 'Entropy', 'Through', 'This']\n",
      "Total Number of Noun Candidates: 110\n"
     ]
    }
   ],
   "source": [
    "noun_candidates = re.findall(r'\\b[A-Z][a-z]+\\b', text)\n",
    "print(\"Noun Candidates:\", noun_candidates)\n",
    "\n",
    "# Count the total number of noun candidates\n",
    "noun_count = len(noun_candidates)\n",
    "print(\"Total Number of Noun Candidates:\", noun_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf209fe1-f934-44f4-8385-0bb7af687bb0",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Regex Pattern:** \\b[A-Z][a-z]+\\b\n",
    "\n",
    "Matches words starting with a capital letter, excluding acronyms.\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "Identify probable nouns, useful for downstream tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3e0ff3-e62c-4c51-9641-df7b710192e7",
   "metadata": {},
   "source": [
    "**Task 10: Highlighting All Proper Nouns in the Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fbac091-d4ff-4c14-a19a-95cc860889ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with Highlighted Proper Nouns: [This] chapter outlines the methodology used in the development of the system. [It] includes details on the adopted methodology, data collection, preprocessing techniques, CNN architecture, and evaluation metrics. [The] [Rapid] [Application] [Development] (RAD) methodology was employed to ensure iterative progress and adaptability throughout the project lifecycle.\n",
      "\n",
      "[The] system development process followed the [Rapid] [Application] [Development] (RAD) methodology, focusing on iterative developme\n"
     ]
    }
   ],
   "source": [
    "highlighted_text = re.sub(r'\\b[A-Z][a-z]+\\b', r'[\\g<0>]', text)\n",
    "print(\"Text with Highlighted Proper Nouns:\", highlighted_text[:500])  # Showing a snippet for brevity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e61e0-b053-4cb5-9887-1ce521862f6e",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Regex Pattern:** \\b[A-Z][a-z]+\\b\n",
    "\n",
    "Wraps each match (proper noun) with square brackets.\n",
    "\n",
    "**Purpose:**\n",
    "Emphasize proper nouns visually for quick identification or readability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c5021-40e4-413d-89f5-420ac945d9b0",
   "metadata": {},
   "source": [
    "**Task 11:Extract Sentences Containing Numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d75c0e11-7f14-4d1b-9f9c-555700d44bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences Containing Numbers: [' The primary steps included:\\n\\n1.', '\\n2.', '\\n3.', '\\n4.', ' Developed by Penn State University and EPFL, the dataset contains 38 classes of diseased and healthy leaves from 14 plants.', ' For this research, the focus was on potato crops, with the following distribution:\\n\\n- Early Blight: 1,000 images\\n- Late Blight: 1,000 images\\n- Healthy: 152 images\\n\\nTo address overfitting and improve the diversity of the training set, various augmentation techniques were applied using the Keras ImageDataGenerator.', ' The following metrics were employed:\\n\\n1.', '\\n2.', '\\n3.', '\\n4.', ' F1 Score: Combines precision and recall to provide a balanced evaluation.', '\\n\\nThe CNN configuration includes:\\n\\n- Convolution Layers: 3 layers with 3 × 3 filters each.', '\\n- Max-Pooling Layers: 3 layers with 2 × 2 pool sizes each.', '\\n- Fully Connected Layers: 512, 256, and 128 neurons, respectively.', '\\n- Batch Size: 32.', '\\n- Epochs: 50.']\n",
      "Total Number of Sentences Containing Numbers: 16\n"
     ]
    }
   ],
   "source": [
    "sentences_with_numbers = re.findall(r'[^.!?]*\\d+[^.!?]*[.!?]', text)\n",
    "print(\"Sentences Containing Numbers:\", sentences_with_numbers)\n",
    "\n",
    "# Count the total number of sentences containing numbers\n",
    "num_sentences_with_numbers = len(sentences_with_numbers)\n",
    "print(\"Total Number of Sentences Containing Numbers:\", num_sentences_with_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f9f23-6978-4973-8185-2559781e4ad8",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Regex Pattern:** [^.!?]*\\d+[^.!?]*[.!?]\n",
    "\n",
    "Matches sentences containing at least one number, surrounded by text.\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "Extract numeric-related context for analysis, like statistics or measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ffd4df-3789-4c71-b7b8-969b40ea059d",
   "metadata": {},
   "source": [
    "**Task 12:Extract All Bullet Points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cb2bf6a-f173-400a-9123-2e5eabd6a226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bullet Points: ['\\n- Early Blight: 1,000 images', '- Late Blight: 1,000 images', '- Healthy: 152 images', '\\n- Rotation: Rotating images at specific angles to account for variations in how objects might appear in real-world scenarios.', '- Shifting: Randomly moving images within a defined range, horizontally or vertically.', '- Shear Transformation: Stretching one axis of the image to simulate distortions.', '- Zoom: Magnifying parts of the image to focus on finer details.', '- Flipping: Horizontally flipping images to ensure the model becomes invariant to directional changes.', '- Brightness Adjustment: Modifying brightness levels to simulate varying lighting conditions.', '\\n- Flatten Layer: Converts the convolved matrix into a one-dimensional array.', '- Fully Connected Layers: Three dense layers with ReLU activation, followed by an output layer with Softmax activation.', '\\n- Convolution Layers: 3 layers with 3 × 3 filters each.', '- Max-Pooling Layers: 3 layers with 2 × 2 pool sizes each.', '- Fully Connected Layers: 512, 256, and 128 neurons, respectively.', '- Output Layer Activation: Softmax.', '- Batch Size: 32.', '- Epochs: 50.', '- Optimizer: Adam.', '- Loss Function: Categorical Cross-Entropy.']\n",
      "Total Number of Bullet Points: 19\n"
     ]
    }
   ],
   "source": [
    "bullet_points = re.findall(r'^\\s*[\\d•-]\\s+.*', text, flags=re.MULTILINE)\n",
    "print(\"Bullet Points:\", bullet_points)\n",
    "\n",
    "# Count the total number of bullet points\n",
    "num_bullet_points = len(bullet_points)\n",
    "print(\"Total Number of Bullet Points:\", num_bullet_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327db7ee-f900-443a-94eb-0b3de84f97d2",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Regex Pattern:** ^\\s*[\\d•-]\\s+.*\n",
    "\n",
    "Matches lines starting with a number, bullet point, or dash.\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "Extract hierarchical points for structured document parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e055f7c-2f05-4477-9f2d-c989ae32bd16",
   "metadata": {},
   "source": [
    "**Task 13: Extract the First Word of Each Sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "147f4078-238f-43e5-9888-3f9d8ab5b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Words of Sentences: ['This', 'chapter', 'outlines', 'the', 'methodology', 'used', 'in', 'the', 'development', 'of', 'the', 'system', 'It', 'includes', 'details', 'on', 'the', 'adopted', 'methodology', 'data', 'collection', 'preprocessing', 'techniques', 'CNN', 'architecture', 'and', 'evaluation', 'metrics', 'The', 'Rapid', 'Application', 'Development', 'RAD', 'methodology', 'was', 'employed', 'to', 'ensure', 'iterative', 'progress', 'and', 'adaptability', 'throughout', 'the', 'project', 'lifecycle', 'The', 'system', 'development', 'process', 'followed', 'the', 'Rapid', 'Application', 'Development', 'RAD', 'methodology', 'focusing', 'on', 'iterative', 'development', 'and', 'rapid', 'prototyping', 'The', 'primary', 'steps', 'included', '1', 'Dataset', 'Preparation', 'The', 'Potato', 'Leaf', 'Images', 'Dataset', 'was', 'downloaded', 'from', 'Kaggle', 'and', 'stored', 'in', 'Google', 'Drive', 'for', 'easy', 'access', '2', 'Data', 'Preprocessing', 'Techniques', 'such', 'as', 'auto', 'orientation', 'resizing', 'and', 'data', 'augmentation']\n",
      "Total Number of Unique First Words: 312\n"
     ]
    }
   ],
   "source": [
    "first_words = [match.group(0) for match in re.finditer(r'\\b\\w+\\b', text)]\n",
    "print(\"First Words of Sentences:\", first_words[:100])  # Showing first 10 for brevity\n",
    "\n",
    "# Count the total number of unique first words\n",
    "unique_first_words = set(first_words)\n",
    "print(\"Total Number of Unique First Words:\", len(unique_first_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfbb869-2c8a-4f61-966f-1932a72370e1",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Regex Pattern:** \\b\\w+\\b\n",
    "\n",
    "Captures the first complete word of a sentence.\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "Analyze sentence structure or text summarization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff39cd62-3c9c-416d-adcb-94a348f11811",
   "metadata": {},
   "source": [
    "**Task 14: Identify Sentences Ending With Specific Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9726d01f-bd74-4e80-8060-066bcd2e0ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences Ending with Specific Words: [' Precision: Measures the consistency of the model in identifying true positives, particularly important in imbalanced datasets.']\n",
      "Total Sentences Ending with Specific Words: 1\n"
     ]
    }
   ],
   "source": [
    "specific_endings = re.findall(r'[^.!?]*\\b(?:datasets|technologies)\\b[.!?]', text, flags=re.IGNORECASE)\n",
    "print(\"Sentences Ending with Specific Words:\", specific_endings)\n",
    "\n",
    "# Count the number of such sentences\n",
    "num_specific_endings = len(specific_endings)\n",
    "print(\"Total Sentences Ending with Specific Words:\", num_specific_endings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25024f-77b5-458c-8579-e1c449bdf2fb",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Regex Pattern:** [^.!?]*\\b(?:datasets|technologies)\\b[.!?]\n",
    "\n",
    "Matches sentences ending with specified keywords.\n",
    "\n",
    "**Purpose:**\n",
    "    \n",
    "Pinpoint focus sentences relevant to given keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca695b-073d-4ae4-93e0-ad25d4aad308",
   "metadata": {},
   "source": [
    "**Task 15: Extract Parenthetical Statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "776720e6-c0e0-4cce-985e-624f28fdb5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parenthetical Statements: ['(RAD)', '(RAD)', '(ReLU)']\n",
      "Total Number of Parenthetical Statements: 3\n"
     ]
    }
   ],
   "source": [
    "parenthetical_statements = re.findall(r'\\([^)]*\\)', text)\n",
    "print(\"Parenthetical Statements:\", parenthetical_statements)\n",
    "\n",
    "# Count the total number of parenthetical statements\n",
    "num_parenthetical_statements = len(parenthetical_statements)\n",
    "print(\"Total Number of Parenthetical Statements:\", num_parenthetical_statements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1901b67-c94c-4476-b02a-6e4e1d47d4a0",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Regex Pattern:** \\([^)]*\\)\n",
    "\n",
    "Captures text enclosed in parentheses.\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "Extract supplementary or explanatory information for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c9e5c-443a-42ba-a293-111c31b1f58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
